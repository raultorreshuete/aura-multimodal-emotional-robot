# AURA - Robot Social Emocional con IA Multimodal
Desarrollo de un sistema rob√≥tico interactivo dise√±ado para la computaci√≥n afectiva. El proyecto integra visi√≥n artificial, an√°lisis de lenguaje corporal y procesamiento de lenguaje natural para detectar el estado emocional del usuario en tiempo real y proponer actividades de ocio personalizadas.

### üîß Hardware e Interfaces (Percepci√≥n)
- ***Visi√≥n Facial:*** Script dedicado (expresioness_faciales.py) para la captura y an√°lisis de micro-expresiones mediante webcam.
- ***An√°lisis Corporal:*** M√≥dulo de inferencia (leguaje_corporal.py) que utiliza un modelo pre-entrenado (.pkl) y coordenadas espaciales (coords.csv) para evaluar la postura y el nivel de energ√≠a del usuario.
- ***Interfaz de Voz (ASR):*** M√≥dulo de escucha activa (voz.py) que gestiona la captura de audio y su transcripci√≥n mediante modelos de IA.
- ***Integraci√≥n Modular:*** Uso de Stanza y Flask (stanza-flask.py) como middleware para orquestar la comunicaci√≥n entre los sensores y el cerebro del robot.

### üèóÔ∏è Arquitectura de Software
- ***Gestor de Di√°logo (Rasa Core):*** Orquestaci√≥n de la conversaci√≥n utilizando historias (stories) que var√≠an seg√∫n el estado de √°nimo detectado, no solo por el texto recibido.
- ***L√≥gica de Recomendaci√≥n:*** El script integrador (integrador.py) fusiona los datos de los m√≥dulos de visi√≥n y voz para tomar decisiones proactivas (ej. sugerir m√∫sica relajante ante signos de estr√©s).
- ***Persistencia de Datos:*** Uso de Slots y memoria a largo plazo para recordar gustos y aversiones ("likes/dislikes") del usuario entre sesiones.

### üöÄ Funcionalidades Clave
- ***Detecci√≥n de Emociones:*** An√°lisis simult√°neo de gestos faciales y postura corporal para inferir estados como alegr√≠a, tristeza o estr√©s.
- ***Recomendaci√≥n Proactiva:*** El sistema sugiere din√°micamente actividades (ej. poner m√∫sica relajante si detecta estr√©s) sin que el usuario lo pida expl√≠citamente.
- ***Modularidad:*** Arquitectura desacoplada donde cada sentido funciona como un microservicio independiente.

### üõ†Ô∏è Herramientas y Tecnolog√≠a
- ***Lenguaje:*** Python 3.x.
- ***Frameworks:*** Rasa (NLP), Flask (Integraci√≥n), Stanza (Procesamiento), OpenCV/MediaPipe (Visi√≥n).
- ***Entorno:*** VS Code y gesti√≥n de dependencias con pip.

### ‚ö†Ô∏è Nota de Instalaci√≥n y Estructura de Archivos
Debido al tama√±o de los modelos de lenguaje pre-entrenados y los entornos virtuales, este repositorio contiene los m√≥dulos esenciales organizados de la siguiente manera:
- ***RASA:*** Incluye el c√≥digo fuente de las Custom Actions (actions.py), archivos de configuraci√≥n (domain.yml, config.yml) y datos de entrenamiento (nlu.yml, stories.yml). No incluye la carpeta models/ ni el entorno virtual.
- ***Lenguaje Corporal:*** Incluye el modelo de clasificaci√≥n entrenado (body_language.pkl), el dataset de coordenadas de referencia (coords.csv) y los scripts de generaci√≥n y detecci√≥n (generarcords.py, leguaje_corporal.py).
- ***Expresiones Faciales:*** Contiene la l√≥gica de visi√≥n computacional para la inferencia de emociones (expresioness_faciales.py).
- ***Voz:*** Script de gesti√≥n de entrada de audio y reconocimiento (voz.py).
- ***Integraci√≥n:*** M√≥dulo puente basado en Flask y Stanza (stanza-flask.py, integrador.py) para la comunicaci√≥n entre componentes.

### üë• Colaboradores
Proyecto acad√©mico desarrollado por Ra√∫l Torres, Miriam Alonso, Borja Hern√°ndez, Bartosz Sliwa, Isaac Heredia y Carlos M√°rquez.
